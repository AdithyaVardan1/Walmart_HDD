{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"D:\\\\MLT assigments\\\\WALMART\\\\1\\\\Second round\\\\prefinal_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [f for f in listdir(data_directory) if isfile(join(data_directory, f))]\n",
    "data_files = [f for f in data_files if \"csv\" in f and f.startswith(\"201\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_to_drop():\n",
    "    data = pd.read_csv(data_directory + \"/2019-01-01.csv\")\n",
    "    drop_columns = [col for col in data.columns if \"normalized\" in col]\n",
    "    return drop_columns     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = get_columns_to_drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the dataframes into a list \n",
    "all_dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in data_files:\n",
    "    data = pd.read_csv(data_directory + \"/\" + file_name)\n",
    "    data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    all_dataframes.append(data.copy())\n",
    "    print(\"{} added to the list of dataframes\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a master data frame to have all the data\n",
    "main_dataframe = pd.concat(all_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_count = main_dataframe[\"model\"].value_counts().to_frame()\n",
    "models_count.columns = [\"count\"]\n",
    "models_count['model_name'] = models_count.index\n",
    "models_count.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_counts = main_dataframe[main_dataframe[\"failure\"]==1].groupby([\"model\"]).agg({'model':'count'})\n",
    "failure_counts.columns = [\"failed_count\"]\n",
    "failure_counts['model_name'] = failure_counts.index\n",
    "failure_counts = failure_counts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_failure_counts = main_dataframe[main_dataframe[\"failure\"]==0].groupby([\"model\"]).agg({'model':'count'})\n",
    "no_failure_counts.columns = [\"no_failed_count\"]\n",
    "no_failure_counts['name'] = no_failure_counts.index\n",
    "no_failure_counts = no_failure_counts.reset_index(drop=True)\n",
    "no_failure_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_1 = pd.merge(no_failure_counts, failure_counts, left_on='model_name', right_on='model_name', how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2 = pd.merge(models_count, merged_data_1, left_on='model_name', right_on='model_name', how=\"left\")\n",
    "merged_data_2 = merged_data_2.fillna(0)\n",
    "merged_data_2[\"failed_count\"] = merged_data_2[\"failed_count\"].astype('int32')\n",
    "merged_data_2 = merged_data_2.sort_values(by='failed_count', ascending=False)\n",
    "merged_data_2.to_csv(r'overall_stats.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ST12000NM0007\"\n",
    "model_1_data = main_dataframe[main_dataframe[\"model\"] == model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_data = model_1_data.dropna(axis=1, how='all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = model_1_data.select_dtypes([np.number]).columns\n",
    "std_deviation = model_1_data[numerical_cols].std()\n",
    "cols_to_drop = std_deviation[std_deviation == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1_data = model_1_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_value_cols = model_1_data.columns[model_1_data.nunique() <= 1].tolist()\n",
    "unique_value_cols.remove('model')\n",
    "unique_value_cols.remove('capacity_bytes')\n",
    "model_1_data = model_1_data.drop(unique_value_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_data = model_1_data.sort_values(['serial_number', 'date'], ascending=[True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(model_name):\n",
    "    model_data = main_dataframe[main_dataframe[\"model\"] == model_name]\n",
    "    model_data = model_data.dropna(axis=1, how='all')\n",
    "    model_data = model_data.dropna()\n",
    "    unique_value_cols = model_data.columns[model_data.nunique() <= 1].tolist()\n",
    "    unique_value_cols.remove('model')\n",
    "    unique_value_cols.remove('capacity_bytes')\n",
    "    model_data = model_data.drop(unique_value_cols, axis=1)\n",
    "    model_data = model_data.sort_values(['serial_number', 'date'], ascending=[True, True])\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_model_data = clean_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_filename = model_name+\"_finalcleaned.csv\"\n",
    "cleaned_model_data.to_csv(export_filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day_data = cleaned_model_data.groupby('serial_number').tail(1)\n",
    "export_filename = model_name+\"last.csv\"\n",
    "last_day_data.to_csv(export_filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # Number of days data needed\n",
    "last_n_days_data = cleaned_model_data.groupby('serial_number').tail(n)\n",
    "for index, row in last_day_data.iterrows():\n",
    "    if row[\"failure\"] == 1:\n",
    "        last_n_days_data[\"failure\"].mask(last_n_days_data[\"serial_number\"] == row[\"serial_number\"], 1, inplace=True)\n",
    "export_filename = model_name+\"_last_\"+ str(n) + \"_days.csv\"\n",
    "last_n_days_data.to_csv(export_filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_to_drop_normalised():\n",
    "    data = pd.read_csv(data_directory +\"/2019-01-01.csv\")\n",
    "    drop_columns = [col for col in data.columns if \"raw\" in col]\n",
    "    return drop_columns \n",
    "\n",
    "columns_to_drop_normalised = get_columns_to_drop_normalised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataframes = []\n",
    "for file_name in data_files:\n",
    "    data = pd.read_csv(data_directory + \"/\" +file_name)\n",
    "    data.drop(columns_to_drop_normalised, axis = 1, inplace=True)\n",
    "    all_dataframes.append(data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ST12000NM0007\"\n",
    "def clean_data_normalised(model_name):\n",
    "    model_data = main_dataframe[main_dataframe[\"model\"] == model_name]\n",
    "    model_data = model_data.dropna(axis=1, how='all')\n",
    "    model_data = model_data.dropna()\n",
    "    unique_value_cols = model_data.columns[model_data.nunique() <= 1].tolist()\n",
    "    unique_value_cols.remove('model')\n",
    "    unique_value_cols.remove('capacity_bytes')\n",
    "    model_data = model_data.drop(unique_value_cols, axis=1)\n",
    "    model_data = model_data.sort_values(['serial_number', 'date'], ascending=[True, True])\n",
    "    return model_data\n",
    "\n",
    "cleaned_normalised_data = clean_data_normalised(model_name)\n",
    "\n",
    "last_day_normalised_data = cleaned_normalised_data.groupby('serial_number').tail(1)\n",
    "export_filename = model_name+\"_lastnorm.csv\"\n",
    "last_day_normalised_data.to_csv(export_filename, index = False)\n",
    "\n",
    "n = 10 # Number of days data needed\n",
    "last_n_days_normalised_data =  cleaned_normalised_data.groupby('serial_number').tail(n)\n",
    "for index, row in last_day_normalised_data.iterrows():\n",
    "    if row[\"failure\"] == 1:\n",
    "        last_n_days_normalised_data[\"failure\"].mask(last_n_days_normalised_data[\"serial_number\"] == row[\"serial_number\"], 1, inplace=True)\n",
    "export_filename = model_name+\"_last_\"+ str(n) + \"_days_normalised.csv\"\n",
    "last_n_days_normalised_data.to_csv(export_filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
